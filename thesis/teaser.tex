\begin{tabular}{lr}
% \includegraphics[width=0.5\linewidth]{logo_sw} % logo bw
 \includegraphics[width=0.5\linewidth]{UT_WBMW_Rot_4C} % logo red
 & \hspace{0.2\linewidth}
 \parbox{0.5\linewidth}{
   \large\bf\textsf{\color{rot}{Mathematisch-\\Naturwissenschaftliche\\Fakultät\\\\
   	\normalsize Methoden des \\ Maschinellen Lernens}}
   \vspace{0.6cm}
 }
\end{tabular}

\vspace*{10ex}
Bachelorarbeit \\

{\huge\bf\textsf{Title of Thesis}}

\vspace*{20ex}

Eberhard Karls Universität Tübingen\\
Mathematisch-Naturwissenschaftliche Fakultät\\
Wilhelm-Schickard-Institut für Informatik\\
Methoden des Maschinellen Lernens\\
Ludwig Bald,~ \verb+ludwig.bald@student.uni-tuebingen.de+,~ 2019

\vspace*{5ex}

\begin{tabular}{@{}l@{\hspace{2em}}l}
  Bearbeitungszeitraum:& von-bis \vspace*{5ex} \\
  Betreuer:& Filip De Roos, Universität Tübingen\\
  Gutachter:& Prof. Dr. Philipp Hennig, Universität Tübingen
\end{tabular}

\thispagestyle{empty}
\newpage

\thesis@blocks@frontMatter

\chapter*{Selbstst\"andigkeitserkl\"arung}
Hiermit versichere ich, dass ich die vorliegende Bachelorarbeit selbst\"andig und
nur mit den angegebenen Hilfsmitteln angefertigt habe und dass alle Stellen,
die dem Wortlaut oder dem Sinne nach anderen Werken entnommen sind,
durch Angaben von Quellen als Entlehnung kenntlich gemacht worden sind.
Diese Bachelorarbeit wurde in gleicher oder \"ahnlicher Form in keinem anderen
Studiengang als Pr\"ufungsleistung vorgelegt.

\vspace*{8ex}
\hrule
\vspace*{2ex}
Ludwig Bald (Matrikelnummer 4125813), \today

\chapter*{Abstract}
\todo{theabstract, citing!}
In machine learning, stochastic gradient descent is a widely used optimizsation algorithm, used to update the parameters of a model after a minibatch of data has been observed, in order to improve the model's predictions. It has been shown to converge much faster when the condition number (i.e. the ratio between the largest and the smallest eigenvalue) of ... is closer to 1. A preconditioner reduces the condition value 
In this thesis I present my implementation of the probabilistic preconditioning algorithm proposed in \cite{de2019active}. I use DeepOBS \todo{cite} as a benchmarking toolbox, examining the effect of this kind of preconditioning on various optimizers and test problems. 
The results...


\chapter*{Acknowledgments}
If you have someone to Acknowledge ;)
\todo{Aaron, Filip}


